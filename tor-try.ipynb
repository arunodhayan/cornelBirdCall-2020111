{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:37.203164Z",
     "iopub.status.busy": "2020-08-17T17:51:37.202342Z",
     "iopub.status.idle": "2020-08-17T17:51:45.470582Z",
     "shell.execute_reply": "2020-08-17T17:51:45.471649Z"
    },
    "papermill": {
     "duration": 8.299972,
     "end_time": "2020-08-17T17:51:45.471857",
     "exception": false,
     "start_time": "2020-08-17T17:51:37.171885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HANDLING IMPORTS...\n",
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "from pydub import AudioSegment\n",
    "from sklearn.utils import shuffle\n",
    "import queue\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import  misc\n",
    "from keras.models import model_from_json\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print (\"HANDLING IMPORTS...\")\n",
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "import math\n",
    "import queue\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "#import Queue as queue\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "from scipy import interpolate\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD,Adam\n",
    "#from keras.optimizers.schedules import ExponentialDecay\n",
    "import keras\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras import backend as K\n",
    "from keras.backend import clear_session\n",
    "from keras import backend\n",
    "# force channels-last ordering\n",
    "backend.set_image_data_format('channels_first')\n",
    "print(backend.image_data_format())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.500964Z",
     "iopub.status.busy": "2020-08-17T17:51:45.500164Z",
     "iopub.status.idle": "2020-08-17T17:51:45.507900Z",
     "shell.execute_reply": "2020-08-17T17:51:45.508373Z"
    },
    "papermill": {
     "duration": 0.023638,
     "end_time": "2020-08-17T17:51:45.508489",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.484851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv',\n",
       " 'example_test_audio_metadata.csv',\n",
       " 'train_audio',\n",
       " 'test.csv',\n",
       " 'example_test_audio_summary.csv',\n",
       " 'example_test_audio',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/birdsong-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.537373Z",
     "iopub.status.busy": "2020-08-17T17:51:45.536544Z",
     "iopub.status.idle": "2020-08-17T17:51:45.540450Z",
     "shell.execute_reply": "2020-08-17T17:51:45.539992Z"
    },
    "papermill": {
     "duration": 0.019814,
     "end_time": "2020-08-17T17:51:45.540587",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.520773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#labels as Pickle file\n",
    "classifier_f = open(\"../input/16thaugust-newactivation/int_to_word_spec_new_spec_bandpass_512_128.pickle\", \"rb\")\n",
    "\n",
    "int_to_word_out = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.572953Z",
     "iopub.status.busy": "2020-08-17T17:51:45.572232Z",
     "iopub.status.idle": "2020-08-17T17:51:45.575266Z",
     "shell.execute_reply": "2020-08-17T17:51:45.574801Z"
    },
    "papermill": {
     "duration": 0.022519,
     "end_time": "2020-08-17T17:51:45.575359",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.552840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "def getRandomState():\n",
    "\n",
    "    RANDOM_SEED = 1337\n",
    "    RANDOM = np.random.RandomState(RANDOM_SEED)\n",
    "\n",
    "    return RANDOM\n",
    "######################## CONFIG #########################\n",
    "RANDOM = getRandomState()\n",
    "\n",
    "\n",
    "SAMPLE_RATE= 44100\n",
    "SPEC_LENGTH= 5.0\n",
    "SPEC_OVERLAP= 0.0\n",
    "SPEC_MINLEN= 1.0\n",
    "SPEC_FMIN= 500\n",
    "SPEC_FMAX= 22000\n",
    "SPEC_TYPE='melspec'\n",
    "\n",
    "SPEC_SIGNAL_THRESHOLD= 0.0001\n",
    "IM_DIM = 1\n",
    "magnitude_scale = 'nonlinear'\n",
    "bandpass=True \n",
    "IM_SIZE = (512, 128)\n",
    "BATCH_SIZE=16\n",
    "NUM_CLASSES=264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.629078Z",
     "iopub.status.busy": "2020-08-17T17:51:45.613380Z",
     "iopub.status.idle": "2020-08-17T17:51:45.679205Z",
     "shell.execute_reply": "2020-08-17T17:51:45.678731Z"
    },
    "papermill": {
     "duration": 0.091687,
     "end_time": "2020-08-17T17:51:45.679301",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.587614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import cv2\n",
    "#import audio\n",
    "################################################\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import cv2\n",
    "RANDOM_SEED = 1337\n",
    "RANDOM = np.random.RandomState(RANDOM_SEED)\n",
    "CACHE = {}\n",
    "def openAudioFile(path, sample_rate=44100, as_mono=True, mean_substract=False):\n",
    "    \n",
    "    # Open file with librosa (uses ffmpeg or libav)\n",
    "    sig, rate = librosa.load(path, sr=sample_rate, mono=as_mono,res_type=\"kaiser_fast\")\n",
    "\n",
    "    # Noise reduction?\n",
    "    if mean_substract:\n",
    "        sig -= sig.mean()\n",
    "\n",
    "    return sig, rate\n",
    "\n",
    "def noise(sig, shape, amount=None):\n",
    "\n",
    "    # Random noise intensity\n",
    "    if amount == None:\n",
    "        amount = RANDOM.uniform(0.1, 0.9)\n",
    "\n",
    "    # Create Gaussian noise\n",
    "    noise = RANDOM.normal(min(sig) * amount, max(sig) * amount, shape)\n",
    "\n",
    "    return noise.astype('float32')\n",
    "\n",
    "def signal2noise(spec):\n",
    "\n",
    "    # Get working copy\n",
    "    spec = spec.copy().astype('float32')\n",
    "\n",
    "    # Calculate median for columns and rows\n",
    "    col_median = np.median(spec, axis=0, keepdims=True)\n",
    "    row_median = np.median(spec, axis=1, keepdims=True)\n",
    "\n",
    "    # Binary threshold\n",
    "    spec[spec < row_median * 1.25] = 0.0\n",
    "    spec[spec < col_median * 1.15] = 0.0\n",
    "    spec[spec > 0] = 1.0\n",
    "\n",
    "    # Median blur\n",
    "    spec = cv2.medianBlur(spec, 3)\n",
    "\n",
    "    # Morphology\n",
    "    spec = cv2.morphologyEx(spec, cv2.MORPH_CLOSE, np.ones((3, 3), np.float32))\n",
    "\n",
    "    # Sum of all values\n",
    "    spec_sum = spec.sum()\n",
    "\n",
    "    # Signal to noise ratio (higher is better)\n",
    "    try:\n",
    "        s2n = spec_sum / (spec.shape[0] * spec.shape[1] * spec.shape[2])\n",
    "    except:\n",
    "        s2n = spec_sum / (spec.shape[0] * spec.shape[1])\n",
    "\n",
    "    return s2n\n",
    "\n",
    "def splitSignal(sig, rate, seconds, overlap, minlen):\n",
    "\n",
    "    # Split signal with overlap\n",
    "    sig_splits = []\n",
    "    for i in range(0, len(sig), int((seconds - overlap) * rate)):\n",
    "        split = sig[i:i + int(seconds * rate)]\n",
    "\n",
    "        # End of signal?\n",
    "        if len(split) < int(minlen * rate):\n",
    "            break\n",
    "        \n",
    "        # Signal chunk too short?\n",
    "        if len(split) < int(rate * seconds):\n",
    "            split = np.hstack((split, noise(split, (int(rate * seconds) - len(split)), 0.5)))\n",
    "        \n",
    "        sig_splits.append(split)\n",
    "\n",
    "    return sig_splits\n",
    "\n",
    "\n",
    "def buildBandpassFilter(rate, fmin, fmax, order=4):\n",
    "\n",
    "    global CACHE\n",
    "\n",
    "    fname = 'bandpass_' + str(rate) + '_' + str(fmin) + '_' + str(fmax)\n",
    "    if not fname in CACHE:\n",
    "        wn = np.array([fmin, fmax]) / (rate / 2.0)\n",
    "        filter_sos = scipy.signal.butter(order, wn, btype='bandpass', output='sos')\n",
    "\n",
    "        # Save to cache\n",
    "        CACHE[fname] = filter_sos\n",
    "\n",
    "    return CACHE[fname]\n",
    "\n",
    "def applyBandpassFilter(sig, rate, fmin, fmax):\n",
    "\n",
    "    # Build filter or load from cache\n",
    "    filter_sos = buildBandpassFilter(rate, fmin, fmax)\n",
    "\n",
    "    return scipy.signal.sosfiltfilt(filter_sos, sig)\n",
    "\n",
    "def pcen(spec, rate, hop_length, gain=0.8, bias=10, power=0.25, t=0.060, eps=1e-6):\n",
    "    s = 1 - np.exp(- float(hop_length) / (t * rate))\n",
    "    M = scipy.signal.lfilter([s], [1, s - 1], spec)\n",
    "    smooth = (eps + M)**(-gain)\n",
    "    return (spec * smooth + bias)**power - bias**power\n",
    "\n",
    "def getMelFilterbank(num_banks, fmin, fmax, f_vec, dtype=np.float32):\n",
    "    '''\n",
    "    An arguably better version of librosa's melfilterbanks wherein issues with \"hard snapping\" are avoided. Works with\n",
    "    an existing vector of frequency bins, as returned from signal.spectrogram(), instead of recalculating them and\n",
    "    flooring down the bin indices.\n",
    "    '''\n",
    "\n",
    "    global CACHE\n",
    "\n",
    "    # Filterbank already in cache?\n",
    "    fname = 'mel_' + str(num_banks) + '_' + str(fmin) + '_' + str(fmax)\n",
    "    if not fname in CACHE:\n",
    "        \n",
    "        # Break frequency and scaling factor\n",
    "        A = 4581.0\n",
    "        f_break = 1750.0\n",
    "\n",
    "        # Convert Hz to mel\n",
    "        freq_extents_mel = A * np.log10(1 + np.asarray([fmin, fmax], dtype=dtype) / f_break)\n",
    "\n",
    "        # Compute points evenly spaced in mels\n",
    "        melpoints = np.linspace(freq_extents_mel[0], freq_extents_mel[1], num_banks + 2, dtype=dtype)\n",
    "\n",
    "        # Convert mels to Hz\n",
    "        banks_ends = (f_break * (10 ** (melpoints / A) - 1))\n",
    "\n",
    "        filterbank = np.zeros([len(f_vec), num_banks], dtype=dtype)\n",
    "        for bank_idx in range(1, num_banks+1):\n",
    "            # Points in the first half of the triangle\n",
    "            mask = np.logical_and(f_vec >= banks_ends[bank_idx - 1], f_vec <= banks_ends[bank_idx])\n",
    "            filterbank[mask, bank_idx-1] = (f_vec[mask] - banks_ends[bank_idx - 1]) / \\\n",
    "                (banks_ends[bank_idx] - banks_ends[bank_idx - 1])\n",
    "\n",
    "            # Points in the second half of the triangle\n",
    "            mask = np.logical_and(f_vec >= banks_ends[bank_idx], f_vec <= banks_ends[bank_idx+1])\n",
    "            filterbank[mask, bank_idx-1] = (banks_ends[bank_idx + 1] - f_vec[mask]) / \\\n",
    "                (banks_ends[bank_idx + 1] - banks_ends[bank_idx])\n",
    "\n",
    "        # Scale and normalize, so that all the triangles do not have same height and the gain gets adjusted appropriately.\n",
    "        temp = filterbank.sum(axis=0)\n",
    "        non_zero_mask = temp > 0\n",
    "        filterbank[:, non_zero_mask] /= np.expand_dims(temp[non_zero_mask], 0)\n",
    "\n",
    "        # Save to cache\n",
    "        CACHE[fname] = (filterbank, banks_ends[1:-1])\n",
    "\n",
    "    return CACHE[fname][0], CACHE[fname][1]\n",
    "\n",
    "def spectrogram(sig, rate, shape=(128, 512), win_len=512, fmin=500, fmax=22000, frequency_scale='mel', magnitude_scale='nonlinear', bandpass=True):\n",
    "\n",
    "    # Compute overlap\n",
    "    hop_len = int(len(sig) / (shape[1] - 1)) \n",
    "    win_overlap = win_len - hop_len + 2\n",
    "    #print('WIN_LEN:', win_len, 'HOP_LEN:', hop_len, 'OVERLAP:', win_overlap)\n",
    "\n",
    "    # Adjust N_FFT?\n",
    "    if frequency_scale == 'mel':\n",
    "        n_fft = win_len\n",
    "    else:\n",
    "        n_fft = shape[1] * 2\n",
    "\n",
    "    # Bandpass filter?\n",
    "    if bandpass:\n",
    "        sig = applyBandpassFilter(sig, rate, fmin, fmax)\n",
    "\n",
    "    # Compute spectrogram\n",
    "    f, t, spec = scipy.signal.spectrogram(sig,\n",
    "                                          fs=rate,\n",
    "                                          window=scipy.signal.windows.hann(win_len),\n",
    "                                          nperseg=win_len,\n",
    "                                          noverlap=win_overlap,\n",
    "                                          nfft=n_fft,\n",
    "                                          detrend=False,\n",
    "                                          mode='magnitude')\n",
    "\n",
    "    # Scale frequency?\n",
    "    if frequency_scale == 'mel':\n",
    "\n",
    "        # Determine the indices of where to clip the spec\n",
    "        valid_f_idx_start = f.searchsorted(fmin, side='left')\n",
    "        valid_f_idx_end = f.searchsorted(fmax, side='right') - 1\n",
    "\n",
    "        # Get mel filter banks\n",
    "        mel_filterbank, mel_f = getMelFilterbank(shape[0], fmin, fmax, f, dtype=spec.dtype)\n",
    "\n",
    "        # Clip to non-zero range so that unnecessary multiplications can be avoided\n",
    "        mel_filterbank = mel_filterbank[valid_f_idx_start:(valid_f_idx_end + 1), :]\n",
    "\n",
    "        # Clip the spec representation and apply the mel filterbank.\n",
    "        # Due to the nature of np.dot(), the spec needs to be transposed prior, and reverted after\n",
    "        spec = np.transpose(spec[valid_f_idx_start:(valid_f_idx_end + 1), :], [1, 0])\n",
    "        spec = np.dot(spec, mel_filterbank)\n",
    "        spec = np.transpose(spec, [1, 0])        \n",
    "\n",
    "    # Magnitude transformation\n",
    "    if magnitude_scale == 'pcen':\n",
    "        \n",
    "        # Convert scale using per-channel energy normalization as proposed by Wang et al., 2017\n",
    "        # We adjust the parameters for bird voice recognition based on Lostanlen, 2019\n",
    "        spec = pcen(spec, rate, hop_len)\n",
    "        \n",
    "    elif magnitude_scale == 'log':\n",
    "        \n",
    "        # Convert power spec to dB scale (compute dB relative to peak power)\n",
    "        spec = spec ** 2\n",
    "        spec = 10.0 * np.log10(np.maximum(1e-10, spec) / np.max(spec))\n",
    "        spec = np.maximum(spec, spec.max() - 100) # top_db = 100\n",
    "\n",
    "    elif magnitude_scale == 'nonlinear':\n",
    "\n",
    "        # Convert magnitudes using nonlinearity as proposed by Schlüter, 2018\n",
    "        a = -1.2 # Higher values yield better noise suppression\n",
    "        s = 1.0 / (1.0 + np.exp(-a))\n",
    "        spec = spec ** s\n",
    "\n",
    "    # Flip spectrum vertically (only for better visialization, low freq. at bottom)\n",
    "    spec = spec[::-1, ...]\n",
    "\n",
    "    # Trim to desired shape if too large\n",
    "    spec = spec[:shape[0], :shape[1]]\n",
    "\n",
    "    # Normalize values between 0 and 1\n",
    "    spec -= spec.min()\n",
    "    if not spec.max() == 0:\n",
    "        spec /= spec.max()\n",
    "    else:\n",
    "        spec = np.clip(spec, 0, 1)\n",
    "\n",
    "    return spec\n",
    "\n",
    "\n",
    "def get_spec(sig, rate, shape, spec_type='linear', **kwargs):\n",
    "\n",
    "    if spec_type.lower()== 'melspec':\n",
    "        #return melspec(sig, rate, shape, **kwargs)\n",
    "        return spectrogram(sig, rate, frequency_scale='mel', **kwargs)\n",
    "    else:\n",
    "        return stft(sig, rate, shape, **kwargs)\n",
    "\n",
    "def signal2noise(spec):\n",
    "\n",
    "    # Get working copy\n",
    "    spec = spec.copy().astype('float32')\n",
    "\n",
    "    # Calculate median for columns and rows\n",
    "    col_median = np.median(spec, axis=0, keepdims=True)\n",
    "    row_median = np.median(spec, axis=1, keepdims=True)\n",
    "\n",
    "    # Binary threshold\n",
    "    spec[spec < row_median * 1.25] = 0.0\n",
    "    spec[spec < col_median * 1.15] = 0.0\n",
    "    spec[spec > 0] = 1.0\n",
    "\n",
    "    # Median blur\n",
    "    spec = cv2.medianBlur(spec, 3)\n",
    "\n",
    "    # Morphology\n",
    "    spec = cv2.morphologyEx(spec, cv2.MORPH_CLOSE, np.ones((3, 3), np.float32))\n",
    "\n",
    "    # Sum of all values\n",
    "    spec_sum = spec.sum()\n",
    "\n",
    "    # Signal to noise ratio (higher is better)\n",
    "    try:\n",
    "        s2n = spec_sum / (spec.shape[0] * spec.shape[1] * spec.shape[2])\n",
    "    except:\n",
    "        s2n = spec_sum / (spec.shape[0] * spec.shape[1])\n",
    "\n",
    "    return s2n\n",
    "\n",
    "def specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n",
    "\n",
    "    # Split signal in consecutive chunks with overlap\n",
    "    sig_splits = splitSignal(sig, rate, seconds, overlap, minlen)\n",
    "\n",
    "    # Extract specs for every sig split\n",
    "    for sig in sig_splits:\n",
    "\n",
    "        # Get spec for signal chunk\n",
    "        spec = get_spec(sig, rate, shape, **kwargs)\n",
    "\n",
    "        yield spec\n",
    "\n",
    "def specsFromFile(path, rate, seconds, overlap, minlen, shape, start=-1, end=-1, **kwargs):\n",
    "\n",
    "    # Open file\n",
    "    sig, rate = openAudioFile(path, rate)\n",
    "\n",
    "    # Trim signal?\n",
    "    if start > -1 and end > -1:\n",
    "        sig = sig[int(start * rate):int(end * rate)]\n",
    "        minlen = 0\n",
    "\n",
    "    # Yield all specs for file\n",
    "    for spec in specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n",
    "        yield spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.712698Z",
     "iopub.status.busy": "2020-08-17T17:51:45.711925Z",
     "iopub.status.idle": "2020-08-17T17:51:45.715034Z",
     "shell.execute_reply": "2020-08-17T17:51:45.714572Z"
    },
    "papermill": {
     "duration": 0.023271,
     "end_time": "2020-08-17T17:51:45.715134",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.691863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish(Layer):\n",
    "    '''\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X_input = Input(input_shape)\n",
    "        >>> X = Mish()(X_input)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Mish, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.744959Z",
     "iopub.status.busy": "2020-08-17T17:51:45.744217Z",
     "iopub.status.idle": "2020-08-17T17:51:45.747220Z",
     "shell.execute_reply": "2020-08-17T17:51:45.746648Z"
    },
    "papermill": {
     "duration": 0.019652,
     "end_time": "2020-08-17T17:51:45.747307",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.727655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "        return keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.779309Z",
     "iopub.status.busy": "2020-08-17T17:51:45.778476Z",
     "iopub.status.idle": "2020-08-17T17:51:45.780911Z",
     "shell.execute_reply": "2020-08-17T17:51:45.781409Z"
    },
    "papermill": {
     "duration": 0.02139,
     "end_time": "2020-08-17T17:51:45.781515",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.760125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LearningRateDecay:\n",
    "        def plot(self, epochs, title=\"Learning Rate Schedule\"):\n",
    "                # compute the set of learning rates for each corresponding\n",
    "                # epoch\n",
    "                lrs = [self(i) for i in epochs]\n",
    "\n",
    "                # the learning rate schedule\n",
    "                plt.style.use(\"ggplot\")\n",
    "                plt.figure()\n",
    "                plt.plot(epochs, lrs)\n",
    "                plt.title(title)\n",
    "                plt.xlabel(\"Epoch #\")\n",
    "                plt.ylabel(\"Learning Rate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.814660Z",
     "iopub.status.busy": "2020-08-17T17:51:45.813842Z",
     "iopub.status.idle": "2020-08-17T17:51:45.816514Z",
     "shell.execute_reply": "2020-08-17T17:51:45.815946Z"
    },
    "papermill": {
     "duration": 0.022248,
     "end_time": "2020-08-17T17:51:45.816624",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.794376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StepDecay(LearningRateDecay):\n",
    "        def __init__(self, initAlpha=0.01, factor=0.25, dropEvery=10):\n",
    "                # store the base initial learning rate, drop factor, and\n",
    "                # epochs to drop every\n",
    "                self.initAlpha = initAlpha\n",
    "                self.factor = factor\n",
    "                self.dropEvery = dropEvery\n",
    "        def __call__(self, epoch):\n",
    "                # compute the learning rate for the current epoch\n",
    "                exp = np.floor((1 + epoch) / self.dropEvery)\n",
    "                alpha = self.initAlpha * (self.factor ** exp)\n",
    "                # return the learning rate\n",
    "                return float(alpha)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:45.861334Z",
     "iopub.status.busy": "2020-08-17T17:51:45.860738Z",
     "iopub.status.idle": "2020-08-17T17:51:49.344823Z",
     "shell.execute_reply": "2020-08-17T17:51:49.345969Z"
    },
    "papermill": {
     "duration": 3.516406,
     "end_time": "2020-08-17T17:51:49.346175",
     "exception": false,
     "start_time": "2020-08-17T17:51:45.829769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 128, 512)      1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 128, 512)      2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 256)       100416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 32, 128)      401536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 32, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 16, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 16, 64)       1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 16, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 8, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 8, 32)        6423040   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512, 8, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 4, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "mish (Mish)                  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "mish_1 (Mish)                (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 264)               34056     \n",
      "=================================================================\n",
      "Total params: 16,993,800\n",
      "Trainable params: 16,991,048\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''def load_model():\n",
    "    \n",
    "    # load json and create model\n",
    "    json_file = open('16thaugust_newactivation/model_bird_spec_1staugust_spec_bandpass_aalnet_512_128_7x7filter.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"16thaugust_newactivation/model_bird_spec_31sthuly_spec_bandpass_512_128_aalnet-7x7filter-18-1.0461.h5\")\n",
    "    return loaded_model\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "#Layer 1\n",
    "model.add(Conv2D(32, (7,7),input_shape=(1,128, 512),activation=mish, padding='same',kernel_initializer='he_normal'))\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Layer 2\n",
    "model.add(Conv2D(64, (7,7), padding='same',activation=mish,kernel_initializer='he_normal'))\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Layer 3    \n",
    "model.add(Conv2D(128,(7,7), padding='same',activation=mish,kernel_initializer='he_normal'))\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Layer 4\n",
    "model.add(Conv2D(256,(7,7), padding='same',activation=mish, kernel_initializer='he_normal'))\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Layer 5\n",
    "model.add(Conv2D(512,(7,7), padding='same',activation=mish, kernel_initializer='he_normal'))\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(128))\n",
    "model.add(Mish())\n",
    "#model.add(beta_mish())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "    \n",
    "#output\n",
    "model.add(Dense(264, activation='softmax'))\n",
    "# Compile model\n",
    "lrate = 0.0001\n",
    "decay=0.0\n",
    "#decay = lrate/epochs #if want to performlearning rate decay\n",
    "schedule = StepDecay(initAlpha=1e-1, factor=0.25, dropEvery=15)\n",
    "opt = SGD(lr=0.01, momentum=0.9, decay=decay)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) \n",
    "#return model\n",
    "#model.load_weights(\"16thaugust_newactivation/model_bird_spec_31sthuly_spec_bandpass_512_128_aalnet-7x7filter-18-1.0461.h5\")\n",
    "model.summary()\n",
    "#model=load_model()\n",
    "model.load_weights(\"../input/16thaugust-newactivation/model_bird_spec_31sthuly_spec_bandpass_512_128_aalnet-7x7filter-18-1.0461.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:49.383245Z",
     "iopub.status.busy": "2020-08-17T17:51:49.382650Z",
     "iopub.status.idle": "2020-08-17T17:51:49.396924Z",
     "shell.execute_reply": "2020-08-17T17:51:49.396307Z"
    },
    "papermill": {
     "duration": 0.034485,
     "end_time": "2020-08-17T17:51:49.397039",
     "exception": false,
     "start_time": "2020-08-17T17:51:49.362554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TEST = Path(\"/kaggle/input/birdsong-recognition/test_audio\").exists()\n",
    "\n",
    "if TEST:\n",
    "    TEST_DF_DIR = \"/kaggle/input/birdsong-recognition/\"\n",
    "else:\n",
    "    TEST_DF_DIR = \"/kaggle/input/birdcall-check/\"\n",
    "    \n",
    "test_df = pd.read_csv(f\"{TEST_DF_DIR}test.csv\")\n",
    "test_audio = TEST_DF_DIR + \"test_audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:49.434203Z",
     "iopub.status.busy": "2020-08-17T17:51:49.432450Z",
     "iopub.status.idle": "2020-08-17T17:51:49.434854Z",
     "shell.execute_reply": "2020-08-17T17:51:49.435309Z"
    },
    "papermill": {
     "duration": 0.024565,
     "end_time": "2020-08-17T17:51:49.435420",
     "exception": false,
     "start_time": "2020-08-17T17:51:49.410855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# -*- coding: utf-8 -*-\n",
    "#Loading images with CPU background threads during GPU forward passes saves a lot of time\n",
    "#Credit: J. Schlüter (https://github.com/Lasagne/Lasagne/issues/12)\n",
    "def threadedBatchGenerator(generator, num_cached=70):\n",
    "    \n",
    "    #import Queue\n",
    "    queues = queue.Queue(maxsize=num_cached)\n",
    "    sentinel = object()  # guaranteed unique reference\n",
    "\n",
    "    #define producer (putting items into queue)\n",
    "    def producer():\n",
    "        for item in generator:\n",
    "            queues.put(item)\n",
    "        queues.put(sentinel)\n",
    "\n",
    "    #start producer (in a background thread)\n",
    "    import threading\n",
    "    thread = threading.Thread(target=producer)\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "    #run as consumer (read items from queue, in current thread)\n",
    "    item = queues.get()\n",
    "    while item is not sentinel:\n",
    "        yield item\n",
    "        queues.task_done()\n",
    "        item = queues.get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:49.484337Z",
     "iopub.status.busy": "2020-08-17T17:51:49.470698Z",
     "iopub.status.idle": "2020-08-17T17:51:49.487189Z",
     "shell.execute_reply": "2020-08-17T17:51:49.486630Z"
    },
    "papermill": {
     "duration": 0.037971,
     "end_time": "2020-08-17T17:51:49.487279",
     "exception": false,
     "start_time": "2020-08-17T17:51:49.449308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(keras.utils.Sequence):\n",
    "    def __init__(self, df, clip, IM_SIZE = (512,128),shape=(128, 512), fmin=500,fmax=22000,seconds=5.0,overlap=0.0,minlen=1.0,win_len=512, frequency_scale='mel', magnitude_scale='nonlinear', bandpass=True,IM_DIM=1):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.IM_SIZE = IM_SIZE\n",
    "        self.fmin=fmin\n",
    "        self.shape=shape\n",
    "        self.fmax=fmax\n",
    "        self.frequency_scale=frequency_scale \n",
    "        self.magnitude_scale=magnitude_scale \n",
    "        self.bandpass=bandpass\n",
    "        self.IM_DIM=IM_DIM\n",
    "        self.win_len=win_len\n",
    "        self.seconds=seconds\n",
    "        self.overlap=overlap\n",
    "        self.minlen=minlen\n",
    "        #self.amptodb = torchaudio.transforms.AmplitudeToDB()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 44100\n",
    "        sample = self.df.iloc[idx]\n",
    "        site = sample.site\n",
    "        row_id = sample.row_id\n",
    "        \n",
    "        if site == \"site_3\":\n",
    "                images=[]\n",
    "                noises=[]\n",
    "                y = self.clip.astype(np.float32)\n",
    "                sig_splits = splitSignal(y, SR, self.seconds, self.overlap, self.minlen)\n",
    "\n",
    "    # Extract specs for every sig split\n",
    "                for sig in sig_splits:\n",
    "                    y=spectrogram(sig, SR, self.shape, self.win_len, self.fmin, self.fmax, self.frequency_scale, self.magnitude_scale, self.bandpass)\n",
    "                    #y= melspec(sig, SR, self.shape, self.fmin, self.fmax, self.normalize, self.preemphasis)\n",
    "                    s2n = signal2noise(y)\n",
    "                    y = y.reshape(-1, self.IM_DIM, self.IM_SIZE[1], self.IM_SIZE[0])\n",
    "                #print (y)\n",
    "                    images.append(y)\n",
    "                    noises.append(s2n)\n",
    "                    #print (len(images))  \n",
    "                #images = np.asarray(images)\n",
    "            #print (len(images))\n",
    "            #images.reshape(-1, self.IM_DIM, self.IM_SIZE[1], self.IM_SIZE[0])\n",
    "\n",
    "                return images, noises, row_id, site\n",
    "        else:\n",
    "            #images=[]\n",
    "            end_seconds = int(sample.seconds)\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            \n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "            #sig_splits = splitSignal(y, SR, self.seconds, self.overlap, self.minlen)\n",
    "            #for sig in sig_splits:\n",
    "                \n",
    "            y=spectrogram(y, SR, self.shape, self.win_len, self.fmin, self.fmax, self.frequency_scale, self.magnitude_scale, self.bandpass)\n",
    "            noises = signal2noise(y)\n",
    "            image = y.reshape(-1, self.IM_DIM, self.IM_SIZE[1], self.IM_SIZE[0])\n",
    "            #images.append(image) \n",
    "            return image, noises, row_id, site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:51:49.528953Z",
     "iopub.status.busy": "2020-08-17T17:51:49.528175Z",
     "iopub.status.idle": "2020-08-17T17:52:21.572422Z",
     "shell.execute_reply": "2020-08-17T17:52:21.571905Z"
    },
    "papermill": {
     "duration": 32.071183,
     "end_time": "2020-08-17T17:52:21.572561",
     "exception": false,
     "start_time": "2020-08-17T17:51:49.501378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 2.84 s, total: 28.7 s\n",
      "Wall time: 32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'site_1_41e6fe6504a34bf6846938ba78d13df1_5': 'nocall',\n",
       " 'site_1_41e6fe6504a34bf6846938ba78d13df1_10': 'nocall',\n",
       " 'site_1_41e6fe6504a34bf6846938ba78d13df1_15': 'aldfly',\n",
       " 'site_1_41e6fe6504a34bf6846938ba78d13df1_20': 'nocall',\n",
       " 'site_1_41e6fe6504a34bf6846938ba78d13df1_25': 'aldfly',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_5': 'aldfly',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_10': 'nocall',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_15': 'aldfly',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_20': 'nocall',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_25': 'nocall',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_30': 'nocall',\n",
       " 'site_1_cce64fffafed40f2b2f3d3413ec1c4c2_35': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_5': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_10': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_15': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_20': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_25': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_30': 'aldfly',\n",
       " 'site_1_99af324c881246949408c0b1ae54271f_35': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_5': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_10': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_15': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_20': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_25': 'aldfly',\n",
       " 'site_1_6ab74e177aa149468a39ca10beed6222_30': 'nocall',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_5': 'aldfly',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_10': 'aldfly',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_15': 'aldfly',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_20': 'nocall',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_25': 'aldfly',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_30': 'aldfly',\n",
       " 'site_1_b2fd3f01e9284293a1e33f9c811a2ed6_35': 'nocall',\n",
       " 'site_2_de62b37ebba749d2abf29d4a493ea5d4_5': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_5': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_10': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_15': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_20': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_25': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_30': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_35': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_40': 'aldfly',\n",
       " 'site_2_8680a8dd845d40f296246dbed0d37394_45': 'aldfly',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_5': 'comyel',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_10': 'aldfly',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_15': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_20': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_25': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_30': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_35': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_40': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_45': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_50': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_55': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_60': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_65': 'nocall',\n",
       " 'site_2_940d546e5eb745c9a74bce3f35efa1f9_70': 'aldfly',\n",
       " 'site_2_07ab324c602e4afab65ddbcc746c31b5_5': 'aldfly',\n",
       " 'site_2_07ab324c602e4afab65ddbcc746c31b5_10': 'aldfly',\n",
       " 'site_2_07ab324c602e4afab65ddbcc746c31b5_15': 'aldfly',\n",
       " 'site_2_07ab324c602e4afab65ddbcc746c31b5_20': 'nocall',\n",
       " 'site_2_07ab324c602e4afab65ddbcc746c31b5_25': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_5': 'aldfly',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_10': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_15': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_20': 'aldfly',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_25': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_30': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_35': 'aldfly',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_40': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_45': 'nocall',\n",
       " 'site_2_899616723a32409c996f6f3441646c2a_50': 'nocall',\n",
       " 'site_3_9cc5d9646f344f1bbb52640a988fe902': 'aldfly',\n",
       " 'site_3_a56e20a518684688a9952add8a9d5213': 'aldfly',\n",
       " 'site_3_96779836288745728306903d54e264dd': 'aldfly',\n",
       " 'site_3_f77783ba4c6641bc918b034a18c23e53': 'aldfly',\n",
       " 'site_3_856b194b097441958697c2bcd1f63982': 'aldfly'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prediction_dict = {}\n",
    "SR=44100\n",
    "for audio_id in test_df.audio_id.unique():\n",
    "        y, sr = librosa.load(test_audio + (audio_id + \".mp3\"),sr=SR)\n",
    "        new_test_df = test_df.query(f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        dataset = TestDataset(new_test_df, y, IM_SIZE = (512,128),shape=(128, 512), fmin=500,fmax=22000,seconds=5.0,overlap=0.0,minlen=1.0,win_len=512, frequency_scale='mel', magnitude_scale='nonlinear', bandpass=True,IM_DIM=1)\n",
    "        for image, noises,  row_id, site in threadedBatchGenerator(dataset):\n",
    "            #print (len(image)) \n",
    "            if site in {\"site_1\", \"site_2\"}:\n",
    "                \n",
    "                y=model.predict(image)\n",
    "                #print (np.max(y))\n",
    "                #print (noises)\n",
    "                #print (int_to_word_out[np.argmax(y)])\n",
    "                if np.max(y)>=0.9:\n",
    "                    \n",
    "                    #print (np.max(y))\n",
    "                    #print ( np.max(y))\n",
    "                    #print (int_to_word_out[np.argmax(y)])\n",
    "                    #print (int_to_word_out[np.argmax(y)])\n",
    "                    prediction_dict[row_id] = ''.join(int_to_word_out[np.argmax(y)])\n",
    "                else:\n",
    "                    prediction_dict[row_id]='nocall'\n",
    "                    #print (prediction_dict[row_id])\n",
    "            else:\n",
    "                results=[]\n",
    "                for s in range (len(image)):\n",
    "                 #for noise in noises:  \n",
    "                \n",
    "                    img = image[s].reshape(-1, IM_DIM, IM_SIZE[1], IM_SIZE[0])\n",
    "                    y=model.predict(img)\n",
    "                    #print ( np.max(y))  \n",
    "                    #print (noises[s])\n",
    "\n",
    "                    if np.max(y)>=0.9:\n",
    "                                #print ( np.max(y))\n",
    "                                #print (int_to_word_out[np.argmax(y)])\n",
    "                                results.append(int_to_word_out[np.argmax(y)])\n",
    "                                mylist = list(dict.fromkeys(results))\n",
    "\n",
    "\n",
    "                \n",
    "                    else: \n",
    "                    \n",
    "                                results.append('nocall')\n",
    "                                \n",
    "                                mylist = list(dict.fromkeys(results))\n",
    "                                \n",
    "                                        \n",
    "                    if len(mylist)>1 and 'nocall' in mylist:\n",
    "                        \n",
    "                        mylist.remove('nocall')\n",
    "                        prediction_dict[row_id] = ','.join(mylist)        \n",
    "                    else:  \n",
    "                        prediction_dict[row_id] = ','.join(mylist)        \n",
    "prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-17T17:52:21.620725Z",
     "iopub.status.busy": "2020-08-17T17:52:21.620076Z",
     "iopub.status.idle": "2020-08-17T17:52:21.672426Z",
     "shell.execute_reply": "2020-08-17T17:52:21.671937Z"
    },
    "papermill": {
     "duration": 0.079118,
     "end_time": "2020-08-17T17:52:21.672557",
     "exception": false,
     "start_time": "2020-08-17T17:52:21.593439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_id = list(prediction_dict.keys())\n",
    "birds = list(prediction_dict.values())\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"row_id\": row_id,\n",
    "    \"birds\": birds\n",
    "})\n",
    "prediction_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 50.9097,
   "end_time": "2020-08-17T17:52:23.514771",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-17T17:51:32.605071",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
